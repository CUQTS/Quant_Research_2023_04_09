{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84685449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\anson\\anaconda3\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\anson\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\anson\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: colorama==0.4.4 in c:\\users\\anson\\anaconda3\\lib\\site-packages (0.4.4)\n",
      "Requirement already satisfied: bayesian-optimization==1.4.0 in c:\\users\\anson\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\anson\\anaconda3\\lib\\site-packages (from bayesian-optimization==1.4.0) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in c:\\users\\anson\\anaconda3\\lib\\site-packages (from bayesian-optimization==1.4.0) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\anson\\anaconda3\\lib\\site-packages (from bayesian-optimization==1.4.0) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\anson\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anson\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.0) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install colorama==0.4.4\n",
    "!pip install bayesian-optimization==1.4.0\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e5a31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for the XG Boost Testing\n",
    "\n",
    "# Where You Store the folder\n",
    "Folder_Path = \"C:\\\\Users\\\\anson\\\\OneDrive\\\\桌面\\\\CUQTS\\\\2023_03_08_FX_Parity\\\\CUQTS-FX-Parity-Research-Source-Code\\\\CUQTS_FXParity-main\\\\Result\"\n",
    "\n",
    "# TimeFrame List & Included Test Currencies\n",
    "tf_list = [\"1M\", \"3M\"]\n",
    "curr_list = [\"USD\", \"JPY\", \"GBP\", \"CHF\",\"AUD\", \"CAD\", \"NZD\", \"NOK\", \"SEK\", \"EUR\"]\n",
    "exp_return_threshold = 0 # When exp.return > threshold -> Classified as 1\n",
    "\n",
    "# ML Metrics - Use as a *kwargs to initialize ML Variable in XGBoost Classifier\n",
    "model_training_parameters = {\n",
    "    'learning_rate': 0.2, \n",
    "    'gamma': 0.2, \n",
    "    'reg_alpha': 0.1\n",
    "}\n",
    "\n",
    "# Additional Choices\n",
    "default_threshold = 0\n",
    "activate_search_threshold = False\n",
    "predict_direction = \"PPP\" # PPP/IRP\n",
    "drop_fe_list = [\"start_date\", \"end_date\", \"realized_spot\"] # Initial Spots, Realized Spots, You may drop as many as you like (Sample Columns is as below)\n",
    "time_lag_dict = {'1M':5, '3M':1} # Will loop through shift 1, 2, ....(time_lag) as user inputs\n",
    "predict_period_after = 1 # Use latest data to predict whether label after kth period will rise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035afef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading treasury rate\n",
    "\n",
    "treasury_dict = {}\n",
    "G_10 = curr_list\n",
    "Maturity = tf_list\n",
    "\n",
    "for currency in G_10:\n",
    "    for maturity in Maturity:\n",
    "        \n",
    "        if currency == 'USD':\n",
    "            ticker = 'USGG' + maturity + ' Index'\n",
    "        else:\n",
    "            ticker = 'GT'+ currency + maturity + ' Govt'\n",
    "        try:\n",
    "            treasury_data_df = pd.read_csv('C:\\\\Users\\\\anson\\\\OneDrive\\\\桌面\\\\CUQTS\\\\2023_03_08_FX_Parity\\\\CUQTS-FX-Parity-Research-Source-Code\\\\CUQTS_FXParity-main\\\\Treasury Rate\\\\' \n",
    "                                        + ticker + '.csv', header = 1, index_col = 0)\n",
    "            treasury_dict[currency+'_'+maturity] = treasury_data_df\n",
    "        except:\n",
    "            treasury_dict[currency+'_'+maturity] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c88cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Adjustment\n",
    "\n",
    "# Generated cross product of currency list\n",
    "curr_pair_1 = curr_list\n",
    "curr_pair_2 = curr_list\n",
    "gen = ((x, y) for x in curr_pair_1 for y in curr_pair_2 if x != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465f0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engine(result_df, time_lag):\n",
    "    req_col = result_df.columns\n",
    "    for col in req_col:\n",
    "        for i in range(1, time_lag + 1):\n",
    "            result_df[f\"{col}_shift{i}\"] = result_df[col].shift(i)\n",
    "    return result_df\n",
    "\n",
    "def label_result(result_df, threshold = default_threshold):\n",
    "    # Here you can add any label as you want...\n",
    "    result_df[\"label\"] = np.where(result_df[\"realized_ret\"] > threshold, 1, 0)\n",
    "    result_df[\"label\"] = result_df[\"label\"].shift(-predict_period_after)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def get_best_params(result_df):\n",
    "    result_df = result_df.dropna()\n",
    "    # set training parameters and label & split the testing set.\n",
    "    X = result_df.drop(columns = [\"label\"])\n",
    "    Y = result_df[\"label\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "    # Optimize the machine learning parameter\n",
    "    # print(X_train, y_train)\n",
    "    def xgb_cv(learning_rate, max_depth):\n",
    "        params = {'learning_rate': learning_rate, 'max_depth': int(max_depth), 'objective': 'binary:logistic'}\n",
    "        cv_result = xgb.XGBClassifier(**params).fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "        return f1_score(y_test, (cv_result > 0.5).astype(int))\n",
    "    # Set up the Bayesian optimizer\n",
    "    pbounds = {'learning_rate': (0.01, 1.0), 'max_depth': (1, 10)}\n",
    "    optimizer = BayesianOptimization(f=xgb_cv, pbounds=pbounds, random_state=42)\n",
    "\n",
    "    # Run the optimization loop\n",
    "    optimizer.maximize(init_points=5, n_iter=10)\n",
    "    best_params = optimizer.max['params']\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    return best_params\n",
    "\n",
    "def get_best_classification(result_df):\n",
    "    result_df = result_df.dropna()\n",
    "    \n",
    "    X = result_df\n",
    "    Y = np.where(result_df[\"realized_ret\"] > default_threshold, 1, 0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "    def optimize_cf(threshold):\n",
    "        param = {'threshold': threshold}\n",
    "        return f1_score(y_train, (X_train[\"realized_ret\"] > 0).astype(int))\n",
    "    pbounds = {'threshold': (-0.005, 0.005)}\n",
    "    \n",
    "    optimizer = BayesianOptimization(f=optimize_cf, pbounds=pbounds, random_state=42)\n",
    "    optimizer.maximize(init_points=5, n_iter=10)\n",
    "    \n",
    "    results = optimizer.res\n",
    "    filtered_results = [result for result in results if result['target'] != 1.0]\n",
    "    best_params = max(filtered_results, key=lambda x: x['target'])['params'][\"threshold\"]\n",
    "    # best_params = optimizer.max['params']\n",
    "    return best_params\n",
    "\n",
    "def trainXGModel(result_df, best_params):\n",
    "    result_df = result_df.dropna()\n",
    "    # set training parameters and label & split the testing set.\n",
    "    X = result_df.drop(columns = [\"label\"])\n",
    "    Y = result_df[\"label\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    \n",
    "    # Fit the model\n",
    "    model = xgb.XGBClassifier(**model_training_parameters)\n",
    "    #model = xgb.XGBClassifier(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the feature importance object\n",
    "    tmp_df = pd.DataFrame(model.feature_importances_.reshape(1, -1), columns=X.columns)\n",
    "    obj = tmp_df.to_dict(orient='records')[0]\n",
    "    \n",
    "    # Predict the model \n",
    "    y_pred = pd.DataFrame(model.predict(X_test), index=y_test.index)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return (accuracy, obj, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cea8fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_study(feature_set, result_df, time_lag):\n",
    "    \n",
    "    result_truncated_df = pd.DataFrame(result_df[feature_set])\n",
    "    result_truncated_df.index = result_df[\"end_date\"]\n",
    "    result_truncated_df = feature_engine(result_truncated_df, time_lag)\n",
    "    possible_feature_set = result_truncated_df.columns\n",
    "    result_truncated_df['label'] = np.where(result_df[\"realized_ret\"] > 0, 1, 0)\n",
    "    result_truncated_df[\"label\"] = result_truncated_df[\"label\"].shift(-predict_period_after)\n",
    "    result_truncated_df = result_truncated_df.dropna()\n",
    "    \n",
    "    accuracy_dict = {}\n",
    "    \n",
    "    for feature in possible_feature_set:\n",
    "        if feature == 'realized_ret':\n",
    "            continue\n",
    "        selected_feature_df = pd.DataFrame(result_truncated_df[[feature,'label']])\n",
    "        accuracy, fe_obj, y_pred = trainXGModel(selected_feature_df, model_training_parameters)\n",
    "        accuracy_dict[feature] = accuracy\n",
    "    \n",
    "    return accuracy_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15253bd0",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e8ac51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = ['spread', 'base_Econ', 'pricing_Econ', 'realized_ret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8463af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ((x, y) for x in curr_pair_1 for y in curr_pair_2 if x != y)\n",
    "\n",
    "accuracy_1M_df = pd.DataFrame()\n",
    "accuracy_3M_df = pd.DataFrame()\n",
    "\n",
    "accuracy_1M_dict = {}\n",
    "accuracy_3M_dict = {}\n",
    "\n",
    "for c1, c2 in gen:\n",
    "    for tf in tf_list:\n",
    "        time_lag = time_lag_dict[tf]\n",
    "        try:\n",
    "            # 1. Access file and create df\n",
    "            \n",
    "            result_df = pd.read_csv(f'{Folder_Path}\\\\{predict_direction}\\\\{c1 + c2}\\\\Data Details\\\\{tf}.csv', index_col=0)\n",
    "            \n",
    "            if predict_direction == \"PPP\":\n",
    "                result_df.index = pd.to_datetime(result_df.index)\n",
    "\n",
    "                tmp = pd.read_csv(f'C:\\\\Users\\\\anson\\\\OneDrive\\\\桌面\\\\CUQTS\\\\2023_03_08_FX_Parity\\\\CUQTS-FX-Parity-Research-Source-Code\\\\CUQTS_FXParity-main\\\\Data\\\\CPI\\\\{c1}.csv', index_col=0, header = 1)\n",
    "                tmp.index = pd.to_datetime(tmp.index)\n",
    "                result_df['base_Econ'] = tmp[\"Last_Price\"].resample(tf).last()\n",
    "\n",
    "                tmp = pd.read_csv(f'C:\\\\Users\\\\anson\\\\OneDrive\\\\桌面\\\\CUQTS\\\\2023_03_08_FX_Parity\\\\CUQTS-FX-Parity-Research-Source-Code\\\\CUQTS_FXParity-main\\\\Data\\\\CPI\\\\{c2}.csv', index_col=0, header = 1)\n",
    "                tmp.index = pd.to_datetime(tmp.index)\n",
    "                result_df['pricing_Econ'] = tmp[\"Last_Price\"].resample(tf).last()\n",
    "            \n",
    "            else:\n",
    "                result_df.index = pd.to_datetime(result_df['start_date'])\n",
    "                \n",
    "                tmp = treasury_dict[c1+'_'+tf]\n",
    "                result_df['base_Econ'] = tmp[\"Last_Price\"].loc[result_df['start_date']]\n",
    "\n",
    "                tmp = treasury_dict[c2+'_'+tf]\n",
    "                result_df['pricing_Econ'] = tmp[\"Last_Price\"].loc[result_df['start_date']]\n",
    "            \n",
    "            result_df.index = result_df[\"end_date\"]\n",
    "            \n",
    "            for feature in feature_set:\n",
    "                \n",
    "                curr_accuracy_dict = feature_importance_study([feature], result_df, time_lag)\n",
    "                \n",
    "                \n",
    "                for key in curr_accuracy_dict.keys():\n",
    "                    \n",
    "                    if tf == '1M':\n",
    "                        if key in accuracy_1M_dict.keys():\n",
    "                            ls = accuracy_1M_dict[key]\n",
    "                            ls.append(curr_accuracy_dict[key])\n",
    "                            accuracy_1M_dict[key] = ls\n",
    "                        else:\n",
    "                            ls = [curr_accuracy_dict[key]]\n",
    "                            accuracy_1M_dict[key] = ls\n",
    "                    else:\n",
    "                        if key in accuracy_3M_dict.keys():\n",
    "                            ls = accuracy_3M_dict[key]\n",
    "                            ls.append(curr_accuracy_dict[key])\n",
    "                            accuracy_3M_dict[key] = ls\n",
    "                        else:\n",
    "                            ls = [curr_accuracy_dict[key]]\n",
    "                            accuracy_3M_dict[key] = ls\n",
    "        except:\n",
    "            continue\n",
    "                \n",
    "\n",
    "                \n",
    "accuracy_1M_df.index = accuracy_1M_dict.keys()\n",
    "accuracy_3M_df.index = accuracy_3M_dict.keys()\n",
    "\n",
    "ls = []\n",
    "\n",
    "for key in accuracy_1M_dict.keys():\n",
    "    ls.append(np.mean(accuracy_1M_dict[key]))\n",
    "    \n",
    "accuracy_1M_df['accuracy'] = ls\n",
    "\n",
    "ls = []\n",
    "\n",
    "for key in accuracy_3M_dict.keys():\n",
    "    ls.append(np.mean(accuracy_3M_dict[key]))\n",
    "    \n",
    "accuracy_3M_df['accuracy'] = ls\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34156914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_Econ_shift2</th>\n",
       "      <td>0.518902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_Econ_shift1</th>\n",
       "      <td>0.517223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_Econ_shift2</th>\n",
       "      <td>0.517003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_Econ_shift4</th>\n",
       "      <td>0.513010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_Econ</th>\n",
       "      <td>0.510666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realized_ret_shift3</th>\n",
       "      <td>0.510346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_Econ_shift4</th>\n",
       "      <td>0.509306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_shift2</th>\n",
       "      <td>0.507615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realized_ret_shift1</th>\n",
       "      <td>0.507262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_shift3</th>\n",
       "      <td>0.502346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_shift5</th>\n",
       "      <td>0.497269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_Econ_shift5</th>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_Econ</th>\n",
       "      <td>0.495524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_shift1</th>\n",
       "      <td>0.495437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realized_ret_shift4</th>\n",
       "      <td>0.493092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_Econ_shift1</th>\n",
       "      <td>0.492446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_shift4</th>\n",
       "      <td>0.492224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread</th>\n",
       "      <td>0.490842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realized_ret_shift2</th>\n",
       "      <td>0.490553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realized_ret_shift5</th>\n",
       "      <td>0.489846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_Econ_shift5</th>\n",
       "      <td>0.489376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_Econ_shift3</th>\n",
       "      <td>0.487896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_Econ_shift3</th>\n",
       "      <td>0.480953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy\n",
       "base_Econ_shift2     0.518902\n",
       "pricing_Econ_shift1  0.517223\n",
       "pricing_Econ_shift2  0.517003\n",
       "base_Econ_shift4     0.513010\n",
       "base_Econ            0.510666\n",
       "realized_ret_shift3  0.510346\n",
       "pricing_Econ_shift4  0.509306\n",
       "spread_shift2        0.507615\n",
       "realized_ret_shift1  0.507262\n",
       "spread_shift3        0.502346\n",
       "spread_shift5        0.497269\n",
       "pricing_Econ_shift5  0.497103\n",
       "pricing_Econ         0.495524\n",
       "spread_shift1        0.495437\n",
       "realized_ret_shift4  0.493092\n",
       "base_Econ_shift1     0.492446\n",
       "spread_shift4        0.492224\n",
       "spread               0.490842\n",
       "realized_ret_shift2  0.490553\n",
       "realized_ret_shift5  0.489846\n",
       "base_Econ_shift5     0.489376\n",
       "pricing_Econ_shift3  0.487896\n",
       "base_Econ_shift3     0.480953"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_1M_df.sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3bba7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spread_shift1</th>\n",
       "      <td>0.531607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_Econ_shift1</th>\n",
       "      <td>0.525926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_Econ</th>\n",
       "      <td>0.505905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_Econ_shift1</th>\n",
       "      <td>0.502236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread</th>\n",
       "      <td>0.502181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pricing_Econ</th>\n",
       "      <td>0.496296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realized_ret_shift1</th>\n",
       "      <td>0.491358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy\n",
       "spread_shift1        0.531607\n",
       "pricing_Econ_shift1  0.525926\n",
       "base_Econ            0.505905\n",
       "base_Econ_shift1     0.502236\n",
       "spread               0.502181\n",
       "pricing_Econ         0.496296\n",
       "realized_ret_shift1  0.491358"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_3M_df.sort_values(by=['accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b5fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
